{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfe4e6f-38aa-4070-891b-ce4b2cec1a2a",
   "metadata": {},
   "source": [
    "# Make Photographs Historical\n",
    "There are 3 major steps in this notebook:\n",
    "1. (optional) Convert images from HEIC image format to PNG\n",
    "2. Preprocess images (so they are cropped and optionally downscaled)\n",
    "3. Apply filters\n",
    "\n",
    "The workflow uses 4 folders, where each transition/copy of images from one to another folder represents a major step.\n",
    "By default, the folder names are:\n",
    "1. 1_raw_input_images\n",
    "2. 2_input_images\n",
    "3. 3_preprocessed_images\n",
    "4. 4_output_images\n",
    "\n",
    "So if you want to skip steps 1 and 2, just place the images you want to apply filters for in folder 3_preprocessed_images.\n",
    "A short explanation of the cells will show you if you need to execute the cell or you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3386dc-4cf1-41de-b244-680124d5c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# MANDATORY\n",
    "# Define folders and initiate folder structure\n",
    "############################################################\n",
    "\n",
    "import os\n",
    "CWD = os.getcwd()\n",
    "RAW_INPUT_IMAGES_PATH = f\"{CWD}/data/1_raw_input_images\"\n",
    "INPUT_IMAGES_PATH = f\"{CWD}/data/2_input_images\"\n",
    "PREPROCESSED_IMAGES_PATH = f\"{CWD}/data/3_preprocessed_images\"\n",
    "OUTPUT_IMAGES_PATH = f\"{CWD}/data/4_output_images\"\n",
    "\n",
    "!mkdir -p {INPUT_IMAGES_PATH}\n",
    "!mkdir -p {RAW_INPUT_IMAGES_PATH}\n",
    "\n",
    "!mkdir -p {PREPROCESSED_IMAGES_PATH}\n",
    "\n",
    "#!rm -rf {OUTPUT_IMAGES_PATH}\n",
    "!mkdir -p {OUTPUT_IMAGES_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c7edcc6-21a7-4d35-9803-b11fd98f4be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: selected Agfa Isolette as the active camera\n",
      "----- STEP HAS FINISHED -----\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# MANDATORY\n",
    "# Set camera options, active camera and blender composition node mapping\n",
    "############################################################\n",
    "\n",
    "CAMERA_SETTINGS = {\n",
    "    'hasselblad_500_cm': {\n",
    "        'model_name': \"Hasselblad 500 C/M\",\n",
    "        'aspect_ratio': { # 1:1 ratio\n",
    "            'x': 9,\n",
    "            'y': 9\n",
    "        },\n",
    "        'blender_node_group': \"Camera: Hasselblad 500 C/M\",\n",
    "        'options': {\n",
    "            'damage_randomizer': 2 # 1 = every picture damaged\n",
    "        }\n",
    "    },\n",
    "    'werra_mat': {\n",
    "        'model_name': \"Werra Mat\",\n",
    "        'aspect_ratio': { # 3:2 ratio\n",
    "            'x': 24,\n",
    "            'y': 36\n",
    "        },\n",
    "        'blender_node_group': \"Camera: Werra Mat\",\n",
    "        'options': {}\n",
    "    },\n",
    "    'agfa_isolette': {\n",
    "        'model_name': \"Agfa Isolette\",\n",
    "        'aspect_ratio': { # 1:1 ratio\n",
    "            'x': 6,\n",
    "            'y': 6\n",
    "        },\n",
    "        'blender_node_group': \"Camera: Agfar Isolette\",\n",
    "        'options': {\n",
    "            'damage_randomizer': 1 # 1 = every picture damaged\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "### SET FIELD HERE #######################################################################\n",
    "ACTIVE_CAMERA_MODEL = CAMERA_SETTINGS[\"agfa_isolette\"]\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "print(f\"INFO: selected {ACTIVE_CAMERA_MODEL['model_name']} as the active camera\")\n",
    "print(f\"----- STEP HAS FINISHED -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79455343-01c0-4b51-87db-a382d23d4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# STEP 1: Convert images from HEIC (RAW_INPUT_IMAGES_PATH) to PNG (INPUT_IMAGES_PATH)\n",
    "############################################################\n",
    "\n",
    "heic_files = [f for f in os.listdir(RAW_INPUT_IMAGES_PATH) if f.endswith('.HEIC') or f.endswith('.heic')]\n",
    "print(f\"INFO: found the following HEIC files {heic_files}\")\n",
    "\n",
    "import pyheif\n",
    "from PIL import Image\n",
    "import piexif\n",
    "\n",
    "def extract_exif_metadata_from_file(file):\n",
    "    for md_block in file.metadata:\n",
    "        if md_block['type'] == 'Exif':\n",
    "           return md_block['data']\n",
    "    raise Exception(\"ERROR: no EXIF metadata found\")\n",
    "    return None\n",
    "\n",
    "print(f\"INFO: starting conversion from HEIC to PNG\")\n",
    "for filename in heic_files:\n",
    "    print(f\"\\tINFO: converting {filename}\")\n",
    "    heic_file = pyheif.read(os.path.join(RAW_INPUT_IMAGES_PATH, filename))\n",
    "    image = Image.frombytes(heic_file.mode, heic_file.size, heic_file.data)\n",
    "    out_file_name = os.path.join(INPUT_IMAGES_PATH, os.path.splitext(filename)[0] + '.png')\n",
    "    image.save(out_file_name)\n",
    "\n",
    "    # Copy EXIF metadata from HEIC file to PNG file\n",
    "    #raw_exif_bytes = extract_exif_metadata_from_file(heic_file)\n",
    "    #exif_data = piexif.load(raw_exif_bytes)\n",
    "    #print(exif_data)\n",
    "    #piexif.insert(raw_exif_bytes, out_file_name)\n",
    "\n",
    "# TODO: Does the metadata need to be copied for some purpose?\n",
    "# I think yes, because we can then calculate delta between old camera and new camera and adjust settings accordingly\n",
    "\n",
    "print(f\"----- STEP HAS FINISHED -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03e3680f-6b82-46d2-a199-04b9d865becd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Kopie (2).JPEG\n",
      "1 - Kopie (3).JPEG\n",
      "1 - Kopie.JPEG\n",
      "1.JPEG\n",
      "INFO: found input files ['1 - kopie (2).jpeg', '1 - kopie (3).jpeg', '1 - kopie.jpeg', '1.jpeg']\n",
      "INFO: starting to apply image filters for camera Hasselblad 500 C/M\n",
      "\tINFO: image 1 - kopie (2).jpeg\n",
      "\tINFO: step 1: cropping image\n",
      "\tINFO: step 2: downscaling image from 1536/1536 to 768/768\n",
      "\tINFO: image 1 - kopie (3).jpeg\n",
      "\tINFO: step 1: cropping image\n",
      "\tINFO: step 2: downscaling image from 1536/1536 to 768/768\n",
      "\tINFO: image 1 - kopie.jpeg\n",
      "\tINFO: step 1: cropping image\n",
      "\tINFO: step 2: downscaling image from 1536/1536 to 768/768\n",
      "\tINFO: image 1.jpeg\n",
      "\tINFO: step 1: cropping image\n",
      "\tINFO: step 2: downscaling image from 1536/1536 to 768/768\n",
      "----- STEP HAS FINISHED -----\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# STEP 2: Preprocess images from (INPUT_IMAGES_PATH) to PNG (PREPROCESSED_IMAGES_PATH)\n",
    "############################################################\n",
    "\n",
    "DOWNSCALING_FACTOR = 2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def crop_to_aspect_ratio(image, w, h):\n",
    "    # Calculate the target aspect ratio\n",
    "    target_aspect_ratio = w / h\n",
    "    \n",
    "    # Get the original dimensions\n",
    "    original_width, original_height = image.size\n",
    "    \n",
    "    # Determine the dimensions for the new aspect ratio\n",
    "    new_width = original_width\n",
    "    new_height = int(new_width / target_aspect_ratio)\n",
    "    \n",
    "    # If the calculated height is greater than the original, recalculate the width instead\n",
    "    if new_height > original_height:\n",
    "        new_height = original_height\n",
    "        new_width = int(new_height * target_aspect_ratio)\n",
    "    \n",
    "    # Calculate the cropping area\n",
    "    left = (original_width - new_width) / 2\n",
    "    top = (original_height - new_height) / 2\n",
    "    right = (original_width + new_width) / 2\n",
    "    bottom = (original_height + new_height) / 2\n",
    "    \n",
    "    # Crop the image to the new aspect ratio\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "    # Save or display the cropped image\n",
    "    #cropped_image.save(output_path)\n",
    "    #cropped_image.show()\n",
    "\n",
    "def get_files_in_folder(folder):\n",
    "    images = []\n",
    "    for f in os.listdir(INPUT_IMAGES_PATH):\n",
    "        print(f)\n",
    "        f = f.lower()\n",
    "        if f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.jpg'):\n",
    "            images.append(f)\n",
    "    return images\n",
    "    #return [f.lower() for f in os.listdir(INPUT_IMAGES_PATH) if f.endswith('.png') or f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "\n",
    "input_files = get_files_in_folder(INPUT_IMAGES_PATH)\n",
    "print(f\"INFO: found input files {input_files}\")\n",
    "\n",
    "print(f\"INFO: starting to apply image filters for camera {ACTIVE_CAMERA_MODEL['model_name']}\")\n",
    "for filename in input_files:\n",
    "    in_file_path = f\"{INPUT_IMAGES_PATH}/{str(filename)}\"\n",
    "    image = Image.open(in_file_path)\n",
    "    \n",
    "    print(f\"\\tINFO: image {filename}\")\n",
    "    print(f\"\\tINFO: step 1: cropping image\")\n",
    "    cropped_image = crop_to_aspect_ratio(image, ACTIVE_CAMERA_MODEL['aspect_ratio']['x'], ACTIVE_CAMERA_MODEL['aspect_ratio']['y'])\n",
    "\n",
    "    # Downscale image\n",
    "    if DOWNSCALING_FACTOR and DOWNSCALING_FACTOR != 1:\n",
    "        cropped_image_w, cropped_image_h = cropped_image.size\n",
    "        if DOWNSCALING_FACTOR > 1:\n",
    "            new_w = cropped_image_w / DOWNSCALING_FACTOR\n",
    "            new_h = cropped_image_h / DOWNSCALING_FACTOR\n",
    "        else:\n",
    "            new_w = cropped_image_w * DOWNSCALING_FACTOR\n",
    "            new_h = cropped_image_h * DOWNSCALING_FACTOR\n",
    "\n",
    "        new_size = (int(new_w), int(new_h))\n",
    "        print(f\"\\tINFO: step 2: downscaling image from {cropped_image_w}/{cropped_image_h} to {new_size[0]}/{new_size[0]}\")\n",
    "        cropped_image = cropped_image.resize(new_size)\n",
    "    \n",
    "    out_file_name = os.path.join(PREPROCESSED_IMAGES_PATH, os.path.splitext(filename)[0] + '.png')\n",
    "    cropped_image.save(out_file_name)\n",
    "\n",
    "\n",
    "print(f\"----- STEP HAS FINISHED -----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea8ea8a-b1b1-4ff0-8c1f-18f523b51fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blender \"/mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/blender/main.blend\" -b --python \"/mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/blender/scripts/batch_composite.py\" -- \"Camera: Agfar Isolette\" \"/mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/3_preprocessed_images\" \"/mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/4_output_images\" 0\n",
      "Color management: using fallback mode for management\n",
      "Color management: Error could not find role data role.\n",
      "Blender 3.0.1\n",
      "Read prefs: /home/tworkool/.config/blender/3.0/config/userpref.blend\n",
      "Color management: scene view \"Filmic\" not found, setting default \"Standard\".\n",
      "/run/user/1000/gvfs/ non-existent directory\n",
      "Read blend: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/blender/main.blend\n",
      "Color management: scene view \"Filmic\" not found, setting default \"Standard\".\n",
      "INFO: executing script with the following params: \n",
      "IMAGE_INPUT_DIRECTORY: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/3_preprocessed_images\n",
      "IMAGE_OUTPUT_DIRECTORY: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/4_output_images\n",
      "FILTER_NAME: Camera: Agfar Isolette\n",
      "DAMAGE_RANDOMIZER: 1\n",
      "INFO: applying filters to 4 images\n",
      "Fra:1 Mem:17.72M (Peak 17.76M) | Time:00:00.00 | Compositing\n",
      "Fra:1 Mem:17.73M (Peak 17.87M) | Time:00:00.00 | Compositing | Determining resolution\n",
      "Fra:1 Mem:17.73M (Peak 17.87M) | Time:00:00.00 | Compositing | Initializing execution\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.35 | Compositing | Tile 1-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.35 | Compositing | Tile 2-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.35 | Compositing | Tile 3-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.36 | Compositing | Tile 4-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.36 | Compositing | Tile 5-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.36 | Compositing | Tile 6-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.36 | Compositing | Tile 7-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.36 | Compositing | Tile 8-9\n",
      "Fra:1 Mem:425.18M (Peak 432.43M) | Time:00:00.42 | Compositing | Tile 9-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 1-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 2-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 3-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 4-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 5-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 6-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 7-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.77 | Compositing | Tile 8-9\n",
      "Fra:1 Mem:427.43M (Peak 434.68M) | Time:00:00.82 | Compositing | Tile 9-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 1-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 2-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 3-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 4-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 5-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 6-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.17 | Compositing | Tile 7-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.18 | Compositing | Tile 8-9\n",
      "Fra:1 Mem:429.68M (Peak 436.93M) | Time:00:01.22 | Compositing | Tile 9-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 1-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 2-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 3-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 4-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 5-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 6-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.58 | Compositing | Tile 7-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.59 | Compositing | Tile 8-9\n",
      "Fra:1 Mem:431.93M (Peak 439.18M) | Time:00:01.63 | Compositing | Tile 9-9\n",
      "Fra:1 Mem:431.87M (Peak 439.18M) | Time:00:01.64 | Compositing | De-initializing execution\n",
      "Saved: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/4_output_images/Image0001.png\n",
      "Saved: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/4_output_images/Image_0010001.png\n",
      "Saved: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/4_output_images/Image_0020001.png\n",
      "Saved: /mnt/c/Users/tworkool/Documents/dev/python/make-photos-historic/data/4_output_images/Image_0030001.png\n",
      "Saved: '/tmp/.png'\n",
      " Time: 00:02.14 (Saving: 00:00.03)\n",
      "\n",
      "\n",
      "Blender quit\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# STEP 3: Apply image filters\n",
    "############################################################\n",
    "\n",
    "BLENDER_SCRIPT_PATH = f\"{CWD}/blender/scripts/batch_composite.py\"\n",
    "BLENDER_SCENE_PATH = f\"{CWD}/blender/main.blend\"\n",
    "ACTIVE_FILTER_NAME = ACTIVE_CAMERA_MODEL['blender_node_group']\n",
    "damage_randomizer = 0\n",
    "if 'options' in ACTIVE_CAMERA_MODEL and 'damage_randomizer' in ACTIVE_CAMERA_MODEL['options']:\n",
    "    damage_randomizer = ACTIVE_CAMERA_MODEL['options']['damage_randomizer']\n",
    "\n",
    "# if the process keeps dying, its probably because jupyter kills the process or times out! In that case just use the command:\n",
    "print(f'blender \"{BLENDER_SCENE_PATH}\" -b --python \"{BLENDER_SCRIPT_PATH}\" -- \"{ACTIVE_FILTER_NAME}\" \"{PREPROCESSED_IMAGES_PATH}\" \"{OUTPUT_IMAGES_PATH}\" 0')\n",
    "\n",
    "# start blender with a scene in background and execute script\n",
    "# call like that 'python test.py -- <FILTER_NAME> <INPUT_PATH> <OUTPUT_PATH> <DAMAGE_RANDOMIZER>\n",
    "! blender \"{BLENDER_SCENE_PATH}\" -b --python \"{BLENDER_SCRIPT_PATH}\" -- \"{ACTIVE_FILTER_NAME}\" \"{PREPROCESSED_IMAGES_PATH}\" \"{OUTPUT_IMAGES_PATH}\" \"{damage_randomizer}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
